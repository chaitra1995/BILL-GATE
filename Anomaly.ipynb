{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbba73d-c195-42be-83f1-e8f0411c707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Anomaly detection is the identification of rare events, items, or observations which are suspicious because they \n",
    "differ significantly from standard behaviors or patterns. Anomalies in data are also called standard deviations,\n",
    "outliers, noise, novelties, and exceptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0b0aa-df6d-4607-9391-15bd3b459cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the key challenges in anomaly detection?\n",
    "Anomaly detection faces several challenges. Firstly, existing methods struggle to handle scenarios where the instances\n",
    "are systems with unobservable characteristics. Secondly, model performance decay over time due to changes in data \n",
    "patterns in time series data is a significant challenge\n",
    "1.Data Quality : One of the main challenges in anomaly detection is the quality of the data that is used to train\n",
    "and test the models. Data quality issues can include noise, outliers, missing values, duplicates, inconsistencies, \n",
    "and imbalances.\n",
    "2.Data Representation: Another challenge in anomaly detection is how to represent the data in a way that captures\n",
    "the relevant features and patterns for identifying anomalies. Data representation can depend on the type, \n",
    "dimensionality, and complexity of the data, as well as the domain knowledge and the goal of the analysis.\n",
    "Some of the methods that can be used to represent the data are feature extraction, feature selection, feature \n",
    "engineering, and dimensionality reduction. These methods can help to reduce the noise, redundancy, and complexity \n",
    "of the data, and to enhance the discriminative power and interpretability of the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cbeb1-685d-42a6-8e9c-3736053bea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "Unsupervised anomaly detection, however, works without labeled data, identifying anomalies based solely on deviations\n",
    "from normal patterns within the dataset. Supervised anomaly detection involves identifying abnormal data behavior\n",
    "using labeled examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f7db8-d0c7-4a14-afcc-41cab14ea766",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "The three anomaly detection methods and algorithms:\n",
    "1.\tUnsupervised Clustering. An unsupervised learning strategy should be used for data lacking prior knowledge,\n",
    "especially when the data points have not been pre-labeled as normal or pathological. The data points with values \n",
    "outside the permitted range of the distribution are marked as outliers, which presupposes that the data has a \n",
    "fixed allocation that can be explained by statistical models\n",
    "2.\tSupervised Classification. This method requires pre-labeled data that are classified as normal or abnormal or\n",
    "even specific known categories of abnormal behavior. It supports both normality and abnormality modeling.\n",
    "Many people consider this a conventional classification problem instead of an anomaly detection system problem \n",
    "since any supervised ML method may be applied to the circumstance.\n",
    "3.\tSemi-supervised Detection. This focuses solely on modeling normalcy, necessitating either pre-classified data\n",
    "that has been designated as normal, or the presumption that the training set exclusively consists of normal data.\n",
    "In the semi-supervised procedure, a supervised model is taught the normal pattern while an unsupervised method is\n",
    "used to infer the normality border. In the supervised step of time-series data learning, time-series forecasting \n",
    "algorithms are frequently employed. The semi-supervised technique can be advantageous in situations where normal \n",
    "data is widely accessible but aberrant data is very difficult to acquire, such as those in defect detection domains.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d092656-780e-4b11-8032-4113a88370f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "Distance-based outlier detection method consults the neighbourhood of an object, which is defined by a given radius.\n",
    "An object is then considered an outlier if its neighborhood does not have enough other points. A distance the threshold\n",
    "that can be defined as a reasonable neighbourhood of the object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28eac7f-fd27-4c29-81f6-31bbbb1b639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density\n",
    "deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a \n",
    "substantially lower density than their neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54613e2-7b0f-4da1-a2ce-6a05b9dfc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "Only requires user to set two variables: the number of trees to build and the sub-sampling size. The authors \n",
    "present experiments with generated Gaussian distribution data that show how convergence for mean path length \n",
    "is achieved relatively quickly with few trees and small subsamples.\n",
    "Isolation Forest is an algorithm for data anomaly detection initially developed by Fei Tony Liu in 2008.\n",
    "Isolation Forest detects anomalies using binary trees. The algorithm has a linear time complexity and a \n",
    "low memory requirement, which works well with high-volume data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4146d-d5cd-4b92-be36-4822e69f0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score \n",
    "using KNN with K=10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ec66b-bf84-4ea8-ab3c-bba02ee9767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv('healthcare.csv')\n",
    "df.head()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df.iloc[:,0], df.iloc[:,1])\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(contamination=0.2)\n",
    "clf.fit(df)\n",
    "predictions = clf.predict(df)\n",
    "\n",
    "predictions\n",
    "import numpy as np\n",
    "index = np.where(predictions < 0)\n",
    "index\n",
    "\n",
    "x=df.values\n",
    "\n",
    "index = np.where(predictions < 0)\n",
    "plt.scatter(df.iloc[:,0], df.iloc[:,1])\n",
    "plt.scatter(x[index,0], x[index,1], edgecolors=\"r\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01999caf-3dec-44c2-83e8-f27689f7016c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f964df-efd7-4035-83f0-21d0ff953afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is a projection and how is it used in PCA?\n",
    "\n",
    "The PCA Decomposition visualizer utilizes principal component analysis to decompose high dimensional data \n",
    "into two or three dimensions so that each instance can be plotted in a scatter plot.\n",
    "The last step of PCA is we need to multiply Q tranpose of Q with the original data matrix in order to get\n",
    "the projection matrix. We go from the (d x k) Q matrix and Q transpose of Q results in d x d dimension.\n",
    "By multiplying the (d x n) X matrix, the projection matrix is d x n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c060f1-98c4-4409-afd2-351b592ef277",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does the optimization problem in PCA work, and what is it trying to achieve?\n",
    "\n",
    "PCA is affected by scale, so you need to scale the features in your data before applying PCA. Use StandardScaler\n",
    "to help you standardize the data set's features onto unit scale ( mean = 0 and variance = 1 ), which is a\n",
    "requirement for the optimal performance of many machine learning algorithms.\n",
    "PCA is used to select statistical significant variables in plant-wide optimisation. Compared to conventional \n",
    "method, the framework can reduce risks and capital cost. The framework is applied in a real case study in\n",
    "a waste oil re-refining plant. The overall product improved 55.25% by yield and 20.6% by quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596efc2a-9513-412c-991a-a1e527c3e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is the relationship between covariance matrices and PCA?\n",
    "\n",
    "PCA is simply described as “diagonalizing the covariance matrix”. What does diagonalizing a matrix mean \n",
    "in this context? It simply means that we need to find a non-trivial linear combination of our original\n",
    "variables such that the covariance matrix is diagonal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bad24d-d278-4325-9ac2-e0979be67b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How does the choice of number of principal components impact the performance of PCA?\n",
    "\n",
    "In PCA, choose the smallest number of components that still capture most of the information in your data.\n",
    "A common approach is to pick enough components to cover about 95% of the total data variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf05690-172b-4598-a4fe-4e2b9b9a9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?\n",
    "\n",
    "If we have 1000 features and we need to bring them down to 100 dimensions, we simply create Principal Components\n",
    "lines with respect to our dimensions and we select best 100 lines where our variance loss is the least.\n",
    "PCA helps to identify the correlation and dependencies among the features in a data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10e004-92d3-4d7b-9414-4601a0f59e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are some common applications of PCA in data science and machine learning?\n",
    "\n",
    "The application of PCA accelerates machine learning operations and algorithms. It prohibits predictive \n",
    "algorithms from having problems with data overfitting. By eliminating superfluous correlated variables,\n",
    "you may boost the efficacy of ML algorithms. PCA frequently results in enhanced data visualization.\n",
    "•\tPCA is used to visualize multidimensional data.\n",
    "•\tIt is used to reduce the number of dimensions in healthcare data.\n",
    "•\tPCA can help resize an image.\n",
    "•\tIt can be used in finance to analyze stock data and forecast returns.\n",
    "•\tPCA helps to find patterns in the high-dimensional datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00037744-8fb9-43da-8e95-1ed6e795272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What is the relationship between spread and variance in PCA?\n",
    "\n",
    "The variance explained can be understood as the ratio of the vertical spread of the regression line \n",
    "(i.e., from the lowest point on the line to the highest point on the line) to the vertical spread of \n",
    "the data (i.e., from the lowest data point to the highest data point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602f8b4-3a9f-46ad-82ea-b3385a38edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How does PCA use the spread and variance of the data to identify principal components?\n",
    "\n",
    "PCA is defined as an orthogonal linear transformation on a real inner product space that transforms \n",
    "the data to a new coordinate system such that the greatest variance by some scalar projection of the\n",
    "data comes to lie on the first coordinate (called the first principal component), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf19fc-2754-429d-a489-5eec12e38f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. How does PCA handle data with high variance in some dimensions but low variance in others?\n",
    "\n",
    "Higher-dimensional data is dominated by a relatively small number of features. PCA is a method that linearly\n",
    "combines these highly correlated variables to form a smaller number of super features called the principal \n",
    "components. The components have the highest variance in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22acfb7-5a4e-484b-984a-7fa7a72606c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

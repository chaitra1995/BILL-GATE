{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7bc6c-8a0b-4712-ace1-0db7bccac80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the basic concept of clustering and give examples of applications where clustering is useful.\n",
    "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the \n",
    "same group (called a cluster) are more similar (in some specific sense defined by the analyst) to each other\n",
    "than to those in other groups (clusters).\n",
    "The applications where clustering is useful.\n",
    "•\tmarket segmentation.\n",
    "•\tsocial network analysis.\n",
    "•\tsearch result grouping.\n",
    "•\tmedical imaging.\n",
    "•\timage segmentation.\n",
    "•\tanomaly detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620184e-4909-4087-a1ff-d2aa4f4156df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is DBSCAN and how does it differ from other clustering algorithms such as k-means and hierarchical clustering?\n",
    "DBSCAN is a density-based clustering algorithm that segregates data points into high-density regions separated by\n",
    "regions of low density. Unlike k-means or hierarchical clustering, which require specifying the number of clusters\n",
    "beforehand, DBSCAN automatically determines clusters based on the density of data points.\n",
    "DBSCAN works by partitioning the data into dense regions of points that are separated by less dense areas.\n",
    "It defines clusters as areas of the dataset where there are many points close to each other, while the points\n",
    "that are far from any cluster are considered outliers or noise\n",
    "Hierarchical cluster basically builds a cluster in the form of a tree known as a dendrogram containing a root\n",
    "node, which has a sub node and in the end the leaf node . In density-based clustering, the objects that have \n",
    "similar density are grouped together.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9642e-1d37-455a-92ce-e81315994c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you determine the optimal values for the epsilon and minimum points parameters in DBSCAN clustering?\n",
    "1.\tMinPts: The larger the data set, the larger the value of minPts should be chosen. minPts must be chosen at least 3.\n",
    "2.\tϵ: The value for ϵ can then be chosen by using a k-distance graph, plotting the distance to the k = minPts \n",
    "nearest neighbor. Good values of ϵ are where this plot shows a strong bend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d0920-27b0-4a1b-bbe8-45ea9fb0cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How does DBSCAN clustering handle outliers in a dataset?\n",
    "DBSCAN groups together data points that are close to each other based on a distance measure and a minimum \n",
    "number of points.\n",
    "It separates regions with low density from those with high density. Data points in low-density regions, which are not \n",
    "assigned to any cluster, are treated as outliers or \"noise\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d1ca4-12f5-464b-9298-ebf486958057",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How does DBSCAN clustering differ from k-means clustering?\n",
    " DBSCAN is a density-based clustering algorithm, whereas K-Means is a centroid-based clustering algorithm.\n",
    "DBSCAN can discover clusters of arbitrary shapes, whereas K-Means assumes that the clusters are spherical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba3157-8ae0-4f32-8826-14d5dbe4050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Can DBSCAN clustering be applied to datasets with high dimensional feature spaces? If so, what are some \n",
    "potential challenges?\n",
    "The algorithm works well even in thousands of dimensions, the problem is that it is very slow. Methods such\n",
    "as spatial indexes that are commonly used to speed up nearest neighbor classification fail in high dimensions\n",
    "Four problems need to be overcome for clustering in high-dimensional data: Multiple dimensions are hard to think\n",
    "in, impossible to visualize, and, due to the exponential growth of the number of possible values with each dimension,\n",
    "complete enumeration of all subspaces becomes intractable with increasing dimensionality\n",
    "Graph-based clustering (Spectral, SNN-cliq, Seurat) is perhaps most robust for high-dimensional data as it \n",
    "uses the distance on a graph, e.g. the number of shared neighbors, which is more meaningful in high dimensions\n",
    "compared to the Euclidean distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22040484-42a4-4b6d-a8c7-a363786772be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How does DBSCAN clustering handle clusters with varying densities?\n",
    "Given the parameters Eps and MinPts, we can discover a cluster in a two-step approach. First, choose an\n",
    "arbitrary point from the database satisfying the core point condition as a seed. Second, retrieve all points\n",
    "that are density-reachable from the seed obtaining the clus- ter containing the seed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83bd7f-b7f0-4dd8-b799-de36c0a40435",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are some common evaluation metrics used to assess the quality of DBSCAN clustering results?\n",
    "Evaluation Metrics For DBSCAN Algorithm In Machine Learning\n",
    "The worst value is -1. Values near 0 denote overlapping clusters. Absolute Rand Score is in the range of 0 to 1.\n",
    "More than 0.9 denotes excellent cluster recovery, and above 0.8 is a good recovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820605a-0f57-4199-9e2a-852a359471ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Can DBSCAN clustering be used for semi-supervised learning tasks?\n",
    "Semi-supervised clustering (SSC), a technique integrating semi-supervised learning and clustering analysis,\n",
    "incorporates the given prior information (e.g., class labels and pairwise constraints) into clustering to guide \n",
    "the clustering process and improve the performance.\n",
    "DBSCAN and other 'unsupervised' clustering methods can be used to automatically propagate labels used by\n",
    "classifiers (a 'supervised' machine learning task) in what as known as 'semi-supervised' machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cee25-d3e3-4a9c-a03b-e187d39916cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. How does DBSCAN clustering handle datasets with noise or missing values?\n",
    "DBSCAN stands for Density-Based Spatial Clustering Application with Noise. It is an unsupervised machine learning\n",
    "algorithm that makes clusters based upon the density of the data points or how close the data is. That said, the\n",
    "points which are outside the dense regions are excluded and treated as noise or outliers\n",
    "DBSCAN creates a circle of epsilon radius around every data point and classifies them into Core point, Border point,\n",
    "and Noise. A data point is a Core point if the circle around it contains at least 'minPoints' number of points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e6e16-478d-43cc-99bf-c0206a4d04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. Implement the DBSCAN algorithm using a python programming language, and apply it to a sample dataset. Discuss the clustering results and interpret the meaning of the obtained clusters.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "df = pd.read_csv('Mall_Customers.csv')\n",
    "X_train = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n",
    "\n",
    "clustering = DBSCAN(eps=12.5, min_samples=4).fit(X_train)\n",
    "DBSCAN_dataset = X_train.copy()\n",
    "DBSCAN_dataset.loc[:,'Cluster'] = clustering.labels_\n",
    "\n",
    "DBSCAN_dataset.Cluster.value_counts().to_frame()\n",
    "outliers = DBSCAN_dataset[DBSCAN_dataset['Cluster']==-1]\n",
    "fig2, (axes) = plt.subplots(1,2,figsize=(12,5))\n",
    "sns.scatterplot('Annual Income (k$)', 'Spending Score (1-100)',data=DBSCAN_dataset[DBSCAN_dataset['Cluster']!=-1]\n",
    "                ,hue='Cluster', ax=axes[0], palette='Set2', legend='full', s=200)\n",
    "sns.scatterplot('Age', 'Spending Score (1-100)', data=DBSCAN_dataset[DBSCAN_dataset['Cluster']!=-1],hue='Cluster', \n",
    "                palette='Set2', ax=axes[1], legend='full', s=200)\n",
    "axes[0].scatter(outliers['Annual Income (k$)'], outliers['Spending Score (1-100)'], s=10, label='outliers', c=\"k\")\n",
    "axes[1].scatter(outliers['Age'], outliers['Spending Score (1-100)'], s=10, label='outliers', c=\"k\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "plt.setp(axes[0].get_legend().get_texts(), fontsize='12')\n",
    "plt.setp(axes[1].get_legend().get_texts(), fontsize='12')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c147f1a-0615-4d8a-a442-9643abbb5a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7532c3-b794-42b7-bd42-e8e1611d0968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4be1d-9b0e-423c-bfe1-2931887bbb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a4049-8974-4300-9c1c-157658de2d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

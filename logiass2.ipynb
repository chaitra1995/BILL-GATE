{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c9d1b-c133-4245-92c0-3a7b4621139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the purpose of grid search cv in machine learning, and how does it work?\n",
    "GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters\n",
    "in a grid. It's essentially a cross-validation technique. The model as well as the parameters must\n",
    "be entered. After extracting the best parameter values, predictions are made\n",
    "It systematically explores a predefined set of hyperparameter values, creating a “grid” of possible\n",
    "combinations. It then evaluates each combination using cross-validation and selects the one that \n",
    "produces the best performance.\n",
    "\n",
    "\n",
    "Q2. Describe the difference between grid search cv and randomize search cv, and when might\n",
    "you choose one over the other?\n",
    "\n",
    "Grid search cv\t                                                      Randomize search cv\n",
    "1.Grid search can search a large number of hyperparameters,\n",
    "but it can become computationally expensive as the number of\n",
    "hyperparameters increases\t                                       1.Random search, on the other hand,\n",
    "                                                              can search a larger number of hyperparameters without\n",
    "                                                            becoming too computationally expensive, as it samples\n",
    "                                                             hyperparameters randomly\n",
    "2.The only requirement of grid search is that it tries every \n",
    "combination in a grid once (and only once).\t                      2.For random search, we input the domain and\n",
    "                                                             each time the algorithm gives us a random combination\n",
    "                                                             of hyperparameter values to try\n",
    "\n",
    "3.Grid Search CV exhaustively evaluates all combinations.\t 3.Random Search CV prioritizes exploration by\n",
    "                                                               randomly sampling combinations, \n",
    "\n",
    " RandomizedSearchCV is better than GridSearchCV? One advantage of RandomizedSearchCV over GridSearchCV\n",
    " is that RandomizedSearchCV can be more efficient if the search space is large since it only samples a \n",
    " subset of the possible combinations rather than evaluating them all\n",
    "\n",
    "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n",
    "In simple words, data leakage can be defined as: \"A scenario when ML model already has information \n",
    "of test data in training data, but this information would not be available at the time of prediction,\n",
    "called data leakage. It causes high performance while training set, but perform poorly in deployment or production\n",
    "\n",
    "\n",
    "Q4. How can you prevent data leakage when building a machine learning model?\n",
    "The following data security practices could prevent data leaks and minimize the chances of data breaches.\n",
    "•\tEvaluate the Risk of Third Parties. ...\n",
    "•\tMonitor all Network Access. ...\n",
    "•\tIdentify All Sensitive Data. ...\n",
    "•\tSecure All Endpoints. ...\n",
    "•\tImplement Data Loss Prevention (DLP) Software. ...\n",
    "•\tEncrypt All Data. ...\n",
    "•\tEvaluate All Permissions.\n",
    "\n",
    "\n",
    "Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "A confusion matrix represents the prediction summary in matrix form. It shows how many prediction are\n",
    "correct and incorrect per class. It helps in understanding the classes that are being confused by model\n",
    "as other class.\n",
    "The usual model performance measures for evaluating a classification model are accuracy, sensitivity or\n",
    "recall, specificity, precision, KS statistic and Area under the curve (AUC).\n",
    "\n",
    "\n",
    "Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "A model with higher recall than precision often makes more positive predictions. A model like this\n",
    "comes with higher false positives and low false negatives. In scenarios like disease prediction,\n",
    "models should always be optimized for recall. False positives are better than false negatives in\n",
    "the healthcare industry.\n",
    "\n",
    "\n",
    "Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "This can be done using a Python library such as Scikit-learn. Analyze the confusion matrix. Look at the \n",
    "diagonal elements of the matrix to see how many instances the model predicted correctly.\n",
    "Look at the off-diagonal elements of the matrix to see how many instances the model predicted incorrectly.\n",
    "Type I and Type II errors are very common in machine learning and statistics. \n",
    "Type I error occurs when the Null Hypothesis (H0) is mistakenly rejected.\n",
    "This is also referred to as the False Positive Error. Type II error occurs when a Null Hypothesis that is actually false is accepted.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?\n",
    "Confusion matrices can be used to calculate performance metrics for classification models. Of the many performance metrics used, the most common are accuracy, precision, recall, and F1 score\n",
    " Accuracy is calculated as the number of correct predictions divided by the total number of predictions made by the model.\n",
    "Precision is calculated as the number of true positives divided by the total number of positive predictions made by the model\n",
    "\n",
    "\n",
    "\n",
    "Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "The accuracy of a model (through a confusion matrix) is calculated using the given formula below. Accuracy can be misleading if used with imbalanced datasets, and therefore there are other metrics based on confusion matrix which can be useful for evaluating performance.\n",
    "\n",
    "Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?\n",
    "A confusion matrix can be used to evaluate the performance of a machine learning model in a number of ways. One way to use a confusion matrix is to calculate the accuracy of the model. This is done by adding the number of true positives and true negatives and dividing by the total number of predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd85cf-338b-4600-9cec-9db07130fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n",
    "Parameter\tLinear (Simple) Regression\t                                  Multiple Regression\n",
    "Definition 1.\tModels the relationship between one\n",
    "dependent and one independent variable.\t                           1. Models the relationship between one dependent\n",
    "                                                                    and two or more independent variables.\n",
    "Equation\t2.Y = C0 + C1X + e\t                                   2. Y = C0 + C1X1 + C2X2 + C3X3 + ….. + CnXn + e\n",
    "Complexity\t3.Simpler dealing with one relationship.\t           3.More complex due to multiple relationships.\n",
    "Use Cases\t4.Suitable when there is one clear predictor.\t       4.Suitable when multiple factors affect the outcome.\n",
    "Assumptions 5.Linearity, Independence, Homoscedasticity,\n",
    "Normality\t                                                       5.Same as linear regression, with the added \n",
    "                                                                    concern of multicollinearity.\n",
    "Visualization\t6.Typically visualized with a 2D \n",
    "                scatter plot and a line of best fit.\t           6.Requires 3D or multi-dimensional space,\n",
    "                                                                     often represented using partial regression plots.\n",
    "Risk of Overfitting\t7.Lower, as it deals with only one predictor.\t7.Higher, especially if too many predictors are\n",
    "                                                                      used without adequate data.\n",
    "Multicollinearity\n",
    "Concern\t 8.Not applicable, as there’s only one predictor.\t        8.A primary concern; having correlated predictors\n",
    "                                                                    can affect the model’s accuracy and interpretation.\n",
    "Applications\t9.Basic research, simple predictions,\n",
    "   understanding a singular relationship.\t                        9.Complex research, multifactorial predictions, \n",
    "                                                                      studying interrelated systems.\n",
    "\n",
    "        \n",
    "Examples :\n",
    "#Linear Regression\n",
    "# Using only TV expenses for prediction\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train_tv = train[['TV']]\n",
    "y_train = train['Sales']\n",
    "X_test_tv = test[['TV']]\n",
    "y_test = test['Sales']\n",
    "\n",
    "linear_model = LinearRegression().fit(X_train_tv, y_train)\n",
    "linear_pred = linear_model.predict(X_test_tv)\n",
    "\n",
    "# Evaluation\n",
    "linear_rmse = np.sqrt(mean_squared_error(y_test, linear_pred))\n",
    "\n",
    "#Multiple Regression\n",
    "# Using both TV and Radio expenses for prediction\n",
    "X_train_multi = train[['TV', 'Radio']]\n",
    "X_test_multi = test[['TV', 'Radio']]\n",
    "\n",
    "multiple_model = LinearRegression().fit(X_train_multi, y_train)\n",
    "multiple_pred = multiple_model.predict(X_test_multi)\n",
    "\n",
    "# Evaluation\n",
    "multiple_rmse = np.sqrt(mean_squared_error(y_test, multiple_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9e501-02b2-4e52-98dc-c51c2c61cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n",
    "\n",
    "Linearity – we draw a scatter plot of residuals and y values. Y values are taken on the vertical y\n",
    "axis, and standardized residuals (SPSS calls them ZRESID) are then plotted on the horizontal x axis.\n",
    "If the scatter plot follows a linear pattern (i.e. not a curvilinear pattern) that shows that \n",
    "linearity assumption is met.  \n",
    "\n",
    "Independence – we worry about this when we have longitudinal dataset. Longitudinal dataset is one\n",
    "where we collect observations from the same entity over time, for instance stock price data – here\n",
    "we collect price info on the same stock i.e. same entity over time.\n",
    "We generally have two types of data: cross sectional and longitudinal. Cross -sectional datasets are\n",
    "those where we collect data on entities only once. For example we collect IQ and GPA information \n",
    "from the students at any one given time (think: camera snap shot)\n",
    "Longitudinal data set is one where we collect GPA information from the same student over time (think: video).\n",
    "\n",
    "In cross sectional datasets we do not need to worry about Independence assumption. It is “assumed” to be met.\n",
    "Normality: we draw a histogram of the residuals, and then examine the normality of the residuals.\n",
    "If the residuals are not skewed, that means that the assumption is satisfied.\n",
    "\n",
    "Even though is slightly skewed, but it is not hugely deviated from being a normal distribution. \n",
    "We can say that this distribution satisfies the normality assumption.\n",
    "Equality of variance: We look at the scatter plot which we drew for linearity (see above) – i.e. y\n",
    "on the vertical axis, and the ZRESID (standardized residuals) on the x axis. \n",
    "If the residuals do not fan out in a triangular fashion that means that the equal variance assumption is met.\n",
    "\n",
    "In the above picture both linearity and equal variance assumptions are met.\n",
    "It is linear because we do not see any curve in there. It also meets equal variance\n",
    "assumption because we do not see the residuals “dots” fanning out in any triangular fashion.\n",
    " \n",
    "Linearity assumption is violated – there is a curve. Equal variance assumption is also violated, \n",
    "the residuals fan out in a “triangular” fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759c66f-442a-4957-b14c-40fc6102612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example\n",
    "using a real-world scenario.\n",
    "\n",
    "When modeling linear data, the slope and intercept of the graph provide useful information about\n",
    "the initial conditions and rate of change of what is being studied. First, the slope of a line is \n",
    "a measure of its steepness. In a line, slope is a ratio of the change in one variable to the change\n",
    "in the other. Usually, this refers to the change in y for each unit change in x, but sometimes other\n",
    "variables may be used.\n",
    "Slope is usually represented by the variable\n",
    "m=Δy/Δx=(y2-y1)/(x2-x1)=(change in y)/(change in x)\n",
    "\n",
    "\n",
    " \n",
    "The intercept refers to the y-intercept, which is where the line intersects the y-axis. Again, \n",
    "other variables may be used, but the intercept generally refers to the independent variable \n",
    "and the vertical axis.\n",
    "Suppose that some doctors are conducting a study. They ask their patients how many servings of\n",
    "fruit or vegetables they consume per day. They also keep track of whether those patients are obese.\n",
    "They record the percentage of their patients who consume 5 or more servings of fruits and vegetables\n",
    "per day and the percentage of their patients who are obese. The data is shown in the graph below.\n",
    "\n",
    " \n",
    " \n",
    "Percent of Adults Getting 5+ Servings of Fruits and Vegetables vs. Percentage of Adults that are Obese\n",
    "The equation of the regression line is given to be y = -0.91x + 38.42.\n",
    "The slope is -0.91. The units of y are % of adults and the units of x are also % of adults. \n",
    "The units of y and the units of x will cancel out when they are divided. Instead, \n",
    "to interpret the slope, state that the percentage of obese adults decreases by 0.91% \n",
    "for every 1% increase in the number of adults who are getting 5 or more servings of fruits and vegetables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2088266-a3b5-4b12-804d-2db672a740d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Explain the concept of gradient descent How is it used in machine learning?\n",
    "\n",
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning \n",
    "models and neural networks. Training data helps these models learn over time, and the cost \n",
    "function within gradient descent specifically acts as a barometer, gauging its accuracy with \n",
    "each iteration of parameter updates.\n",
    "Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function.\n",
    "Gradient descent in machine learning is simply used to find the values of a function's parameters \n",
    "(coefficients) that minimize a cost function as far as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730646c8-f1af-494c-b37b-bf4030a26ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "Multiple regression is a broader class of regressions that encompasses linear and nonlinear regressions\n",
    "with multiple explanatory variables. Whereas linear regress only has one independent variable impacting \n",
    "the slope of the relationship, multiple regression incorporates multiple independent variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096537b9-1b72-4705-b675-0deab7ceb96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. \n",
    "How can you detect and address this issue?\n",
    "\n",
    "Multicollinearity occurs when two or more independent variables have a high correlation with\n",
    "one another in a regression model, which makes it difficult to determine the individual effect\n",
    "of each independent variable on the dependent variable.\n",
    "We can detect  and address this issue:\n",
    "1. Remove highly correlated predictors from the model. If you have two or more factors with a \n",
    "high VIF, remove one from the model. ...\n",
    "2. Use Partial Least Squares Regression (PLS) or Principal Components Analysis, regression\n",
    "methods that cut the number of predictors to a smaller set of uncorrelated components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9163851-e40f-4f31-9b3e-58d572cc1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "A polynomial regression model is a machine learning model that can capture non-linear relationships\n",
    "between variables by fitting a non-linear regression line, which may not be possible with simple\n",
    "linear regression. It is used when linear regression models may not adequately capture the \n",
    "complexity of the relationship.\n",
    "Polynomial Regression is able to model non-linearly seperable data and is much more flexible\n",
    "than linear regression, but some of its disadvantages are we need some knowledge of data in \n",
    "order to select best exponents, and it is prone to over fitting if exponents are poorly selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb8039-b1c2-4ac3-8aaf-11732dad5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "Polynomial regression offers several advantages over linear regression: Non-linear relationships:\n",
    "Polynomial regression can capture non-linear relationships between variables, unlike linear regression,\n",
    "which assumes a linear relationship. This flexibility is helpful when the underlying relationship is\n",
    "curvilinear. A polynomial regression model is a machine learning model that can capture non-linear \n",
    "relationships between variables by fitting a non-linear regression line, which may not be possible\n",
    "with simple linear regression. It is used when linear regression models may not adequately capture\n",
    "the complexity of the relationship.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f2023-5657-4476-8a63-f35f1d730901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "\n",
    "Random forest regression is a supervised learning algorithm and bagging technique that uses an ensemble\n",
    "learning method for regression in machine learning. The trees in random forests run in parallel, meaning\n",
    "there is no interaction between these trees while building the trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6d3cf-989c-459a-9d1a-57fa1acc5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "\n",
    "Random Forest is a popular machine learning algorithm used for classification and regression tasks due\n",
    "to its high accuracy, robustness, feature importance, versatility, and scalability. Random Forest reduces\n",
    "overfitting by averaging multiple decision trees and is less sensitive to noise and outliers in the data.\n",
    "The data simplification method is used to reduce overfitting by decreasing the complexity of the model \n",
    "to make it simple enough that it does not overfit. Some of the procedures include pruning a decision tree, \n",
    "reducing the number of parameters in a neural network, and using dropout on a neutral network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b1acc-24f0-4734-8669-68d9f461fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\n",
    "A random forest is a meta-estimator (i.e. it combines the result of multiple predictions), which aggregates\n",
    "many decision trees with some helpful modifications: The number of features that can be split at each node is\n",
    "limited to some percentage of the total (which is known as the hyper-parameter).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ac86a-81b6-4194-b594-d24566c739b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "\n",
    "In random forest, the hyperparameters are the number of trees, number of features and the type of trees\n",
    "(such as GBM or M5). The number of features is important and should be tuned. In this case, random forest\n",
    "is useful because it automatically tunes the number of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5bba3-148a-42ad-83a5-1ebd1c21576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "Decision Tree\t                                                Random Forest\n",
    "1.A decision tree is a tree-like model of decisions\n",
    "along with possible outcomes in a diagram.\t            1.A classification algorithm consisting of many\n",
    "                                                       decision trees combined to get a more accurate result \n",
    "                                                         as compared to a single tree.\n",
    "2.There is always a scope for overfitting, caused\n",
    "due to the presence of variance.\t                   2.Random forest algorithm avoids and prevents \n",
    "                                                         overfitting by using multiple trees.\n",
    "3.The results are not accurate.\t                       3.This gives accurate and precise results.\n",
    "4.Decision trees require low computation, thus \n",
    "reducing time to implement and carrying low accuracy.\t4.This consumes more computation. The process of \n",
    "                                                          generation and analyzing is time-consuming. \n",
    "5.It is easy to visualize. The only task is to fit\n",
    "the decision tree model.\t                            5.This has complex visualization as it determines\n",
    "                                                          the pattern behind the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41696240-3002-4812-b342-aef9061d70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "Advantages of Random Forest\n",
    "\n",
    "1. Random Forest is based on the bagging algorithm and uses Ensemble Learning technique. \n",
    "It creates as many trees on the subset of the data and combines the output of all the trees. \n",
    "In this way it reduces overfitting problem in decision trees and also reduces the variance and \n",
    "therefore improves the accuracy.\n",
    "\n",
    "2. Random Forest can be used to solve both classification as well as regression problems.\n",
    "\n",
    "3. Random Forest works well with both categorical and continuous variables.\n",
    "\n",
    "4. Random Forest can automatically handle missing values.\n",
    "\n",
    "5. No feature scaling required: No feature scaling (standardization and normalization) required in\n",
    "case of Random Forest as it uses rule based approach instead of distance calculation.\n",
    "\n",
    "6. Handles non-linear parameters efficiently: Non linear parameters don't affect the performance of \n",
    "a Random Forest unlike curve based algorithms. So, if there is high non-linearity between the independent\n",
    "variables, Random Forest may outperform as compared to other curve based algorithms.\n",
    "\n",
    "7. Random Forest can automatically handle missing values.\n",
    "\n",
    "8. Random Forest is usually robust to outliers and can handle them automatically.\n",
    "\n",
    "9. Random Forest algorithm is very stable. Even if a new data point is introduced in the dataset,\n",
    "the overall algorithm is not affected much since the new data may impact one tree, but it is very\n",
    "hard for it to impact all the trees.\n",
    "\n",
    "10. Random Forest is comparatively less impacted by noise.\n",
    "\n",
    "Disadvantages of Random Forest\n",
    "\n",
    "1. Complexity: Random Forest creates a lot of trees (unlike only one tree in case of decision tree) \n",
    "and combines their outputs. By default, it creates 100 trees in Python sklearn library.\n",
    "To do so, this algorithm requires much more computational power and resources. On the other\n",
    "hand decision tree is simple and does not require so much computational resources.\n",
    "\n",
    "2. Longer Training Period: Random Forest require much more time to train as compared to decision\n",
    "trees as it generates a lot of trees (instead of one tree in case of decision tree) and makes decision\n",
    "on the majority of votes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990058e-5ad5-4927-9e25-cb8a9cbcb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What is the output of Random Forest Regressor?\n",
    "\n",
    "For classification tasks, the output of the random forest is the class selected by most trees. \n",
    "For regression tasks, the mean or average prediction of the individual trees is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0932215-140f-4346-b96d-b558302ba38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "\n",
    "Random forests can be used for solving regression (numeric target variable) and classification\n",
    "(categorical target variable) problems. Random forests are an ensemble method, meaning they combine\n",
    "predictions from other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc5e56-3418-48d0-b6aa-51d8fbeb981b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
